{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bài 1: Khôi phục Masked Token (Masked Language Modeling)"
      ],
      "metadata": {
        "id": "4ZIAjAkLwUBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1. Tải pipeline \"fill-mask\" (tự động tải mô hình mặc định phù hợp, thường là BERT variant)\n",
        "mask_filler = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "\n",
        "# 2. Câu đầu vào với token [MASK]\n",
        "input_sentence = \"Hanoi is the [MASK] of Vietnam.\"\n",
        "\n",
        "# 3. Thực hiện dự đoán, lấy 5 dự đoán hàng đầu (top_k=5)\n",
        "predictions = mask_filler(input_sentence, top_k=5)\n",
        "\n",
        "# 4. In kết quả\n",
        "print(f\"Câu gốc: {input_sentence}\")\n",
        "for pred in predictions:\n",
        "    print(f\"Dự đoán: '{pred['token_str']}' với độ tin cậy: {pred['score']:.4f}\")\n",
        "    print(f\" -> Câu hoàn chỉnh: {pred['sequence']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxQu5y-pwUvj",
        "outputId": "6ce730ab-4b81-435d-8fdb-bb87511667c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu gốc: Hanoi is the [MASK] of Vietnam.\n",
            "Dự đoán: 'capital' với độ tin cậy: 0.9991\n",
            " -> Câu hoàn chỉnh: hanoi is the capital of vietnam.\n",
            "Dự đoán: 'center' với độ tin cậy: 0.0001\n",
            " -> Câu hoàn chỉnh: hanoi is the center of vietnam.\n",
            "Dự đoán: 'birthplace' với độ tin cậy: 0.0001\n",
            " -> Câu hoàn chỉnh: hanoi is the birthplace of vietnam.\n",
            "Dự đoán: 'headquarters' với độ tin cậy: 0.0001\n",
            " -> Câu hoàn chỉnh: hanoi is the headquarters of vietnam.\n",
            "Dự đoán: 'city' với độ tin cậy: 0.0001\n",
            " -> Câu hoàn chỉnh: hanoi is the city of vietnam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bài 2: Dự đoán từ tiếp theo (Next Token Prediction)"
      ],
      "metadata": {
        "id": "O2TC49T7yUMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1. Tải pipeline \"text-generation\" (tự động tải mô hình mặc định, thường là GPT-2)\n",
        "generator = pipeline(\"text-generation\")\n",
        "\n",
        "# 2. Đoạn văn bản mồi (prompt)\n",
        "prompt = \"The best thing about learning NLP is\"\n",
        "\n",
        "# 3. Sinh văn bản (max_length=50, num_return_sequences=3)\n",
        "# params:\n",
        "#     max_length: tổng độ dài của câu mồi và phần được sinh ra\n",
        "#     num_return_sequences: số lượng chuỗi kết quả muốn nhận\n",
        "generated_texts = generator(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
        "\n",
        "# 4. In kết quả\n",
        "print(f\"Câu mồi: '{prompt}'\")\n",
        "for text in generated_texts:\n",
        "    print(\"Văn bản được sinh ra:\")\n",
        "    print(text['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE4s4Jl9wZke",
        "outputId": "cf5152c4-f036-4870-d384-212331e86dfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu mồi: 'The best thing about learning NLP is'\n",
            "Văn bản được sinh ra:\n",
            "The best thing about learning NLP is that it's easy and fast.\n",
            "\n",
            "NLP is a simple, easy to learn, and highly practical, language for all skill levels. There are no specific requirements, so learning NLP is easy.\n",
            "\n",
            "This guide is for those who have already learned NLP in class. It covers the basic concepts of NLP, as well as the more advanced concepts such as declarative, imperative, and a bit more.\n",
            "\n",
            "To learn NLP, you need to understand the underlying concepts of C++, and learn the concepts of imperative, declarative, and a bit more.\n",
            "\n",
            "NLP is best learned by using NST and NLP-C++.\n",
            "\n",
            "NLP-C++ is a great, high quality language for C++.\n",
            "\n",
            "So what is NLP?\n",
            "\n",
            "NLP is a programming language suitable for C++.\n",
            "\n",
            "I've read a lot of NLP books and articles about NLP, and I think this is a really good starting point for learning NLP. NLP is a very simple language, and can be used for many different purposes.\n",
            "\n",
            "This is a very good starting point for learning NLP.\n",
            "\n",
            "I'm going to show you how to gain access to NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bài 3: Tính toán Vector biểu diễn của câu (Sentence Representation)"
      ],
      "metadata": {
        "id": "j_JQJF0I2U8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# 1. Chọn một mô hình BERT\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# 2. Câu đầu vào\n",
        "sentences = [\"This is a sample sentence.\"]\n",
        "\n",
        "# 3. Tokenize câu\n",
        "# padding=True: đệm các câu ngắn hơn để có cùng độ dài\n",
        "# truncation=True: cắt các câu dài hơn\n",
        "# return_tensors='pt': trả về kết quả dưới dạng PyTorch tensors\n",
        "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# 4. Đưa qua mô hình để lấy hidden states\n",
        "# torch.no_grad() để không tính toán gradient, tiết kiệm bộ nhớ\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# outputs.last_hidden_state chứa vector đầu ra của tất cả các token\n",
        "last_hidden_state = outputs.last_hidden_state\n",
        "# shape: (batch_size, sequence_length, hidden_size)\n",
        "\n",
        "# 5. Thực hiện Mean Pooling\n",
        "# Để tính trung bình cộng của các vector, cần bỏ qua token đệm (padding tokens)\n",
        "attention_mask = inputs['attention_mask']\n",
        "mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "\n",
        "# Nhân các vector ẩn với mask và tính tổng (chỉ giữ lại vector của các token thực)\n",
        "sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)\n",
        "\n",
        "# Tính tổng của mask để chia trung bình (sử dụng min=1e-9 để tránh chia cho 0)\n",
        "sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "# Vector biểu diễn cuối cùng của câu\n",
        "sentence_embedding = sum_embeddings / sum_mask\n",
        "\n",
        "# 6. In kết quả\n",
        "print(\"Vector biểu diễn của câu:\")\n",
        "print(sentence_embedding)\n",
        "print(\"\\nKích thước của vector:\", sentence_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2Nx8fjMyr4y",
        "outputId": "0633921f-a1d3-409b-a81c-4510be7cf084"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector biểu diễn của câu:\n",
            "tensor([[-6.3874e-02, -4.2837e-01, -6.6779e-02, -3.8430e-01, -6.5784e-02,\n",
            "         -2.1826e-01,  4.7636e-01,  4.8659e-01,  4.0647e-05, -7.4273e-02,\n",
            "         -7.4740e-02, -4.7635e-01, -1.9773e-01,  2.4824e-01, -1.2162e-01,\n",
            "          1.6678e-01,  2.1045e-01, -1.4576e-01,  1.2636e-01,  1.8635e-02,\n",
            "          2.4640e-01,  5.7090e-01, -4.7014e-01,  1.3782e-01,  7.3650e-01,\n",
            "         -3.3808e-01, -5.0331e-02, -1.6452e-01, -4.3517e-01, -1.2900e-01,\n",
            "          1.6516e-01,  3.4004e-01, -1.4930e-01,  2.2422e-02, -1.0488e-01,\n",
            "         -5.1916e-01,  3.2964e-01, -2.2162e-01, -3.4206e-01,  1.1993e-01,\n",
            "         -7.0148e-01, -2.3126e-01,  1.1224e-01,  1.2550e-01, -2.5191e-01,\n",
            "         -4.6374e-01, -2.7261e-02, -2.8415e-01, -9.9249e-02, -3.7017e-02,\n",
            "         -8.9192e-01,  2.5005e-01,  1.5816e-01,  2.2701e-01, -2.8497e-01,\n",
            "          4.5300e-01,  5.0945e-03, -7.9441e-01, -3.1008e-01, -1.7403e-01,\n",
            "          4.3029e-01,  1.6816e-01,  1.0590e-01, -4.8987e-01,  3.1856e-01,\n",
            "          3.2861e-01, -1.3403e-02,  1.8807e-01, -1.0905e+00,  2.1009e-01,\n",
            "         -6.7579e-01, -5.7076e-01,  8.5947e-02,  1.9121e-01, -3.3818e-01,\n",
            "          2.7744e-01, -4.0539e-01,  3.1305e-01, -4.1197e-01, -5.6820e-01,\n",
            "         -3.9074e-01,  4.0747e-01,  9.9898e-02,  2.3719e-01,  1.0154e-01,\n",
            "         -2.5670e-01, -2.0583e-01,  1.1762e-01, -5.1439e-01,  4.0979e-01,\n",
            "          1.2149e-01,  1.9333e-02, -5.9029e-02, -2.0141e-01,  7.0860e-01,\n",
            "         -6.4609e-02,  2.4779e-02, -9.0578e-03,  1.9666e-02,  3.0815e-01,\n",
            "         -4.9832e-02, -1.0691e+00,  6.1072e-01, -4.9722e-02, -1.5156e-01,\n",
            "         -6.7778e-02,  4.7812e-02,  5.2103e-01,  1.6951e-01,  1.0146e-02,\n",
            "          5.3093e-01, -7.8189e-02,  6.5843e-02, -2.9382e-01, -4.6045e-01,\n",
            "          4.2071e-01,  1.1822e-01,  2.3631e-01, -4.5379e-02, -1.3740e-01,\n",
            "         -4.4018e-01, -6.8123e-02,  1.9935e-01,  8.7062e-01, -2.2603e-01,\n",
            "          3.3604e-01,  2.0236e-01,  3.7898e-01,  1.9533e-01, -3.0366e-01,\n",
            "          3.8633e-01,  6.1949e-01,  6.8663e-01, -1.8968e-01, -3.6815e-01,\n",
            "         -1.6616e-01, -7.0827e-02, -3.4610e-01, -8.5326e-01,  4.6645e-02,\n",
            "          2.8512e-01,  1.0890e-01,  2.5938e-01, -4.2975e-01,  4.3345e-01,\n",
            "          2.0637e-01, -3.8656e-01, -3.8187e-02,  3.6925e-01,  3.0130e-01,\n",
            "          4.0251e-01,  1.2887e-01, -3.7689e-01, -3.4447e-01, -4.2116e-01,\n",
            "         -1.0252e-01, -8.9737e-02,  4.7384e-01,  8.1717e-02,  1.5885e-01,\n",
            "          7.6674e-01,  3.4493e-01,  9.8538e-04,  4.8932e-02,  2.6132e-01,\n",
            "          3.8329e-02, -2.0036e-01,  2.6654e-01,  9.3773e-02, -4.6779e-02,\n",
            "         -4.0519e-01, -4.4310e-01,  6.1268e-01, -1.8950e-01, -3.8333e-01,\n",
            "          2.0583e-01,  1.5379e-01, -1.4664e-01,  5.3847e-01, -3.9618e-01,\n",
            "         -2.0599e+00,  6.7052e-01,  2.1112e-01, -4.7306e-01,  3.4865e-01,\n",
            "         -2.9919e-01,  5.4614e-01, -5.3924e-01, -2.4877e-01, -2.9070e-02,\n",
            "         -2.0319e-01, -7.3275e-02, -3.8147e-01, -5.4454e-01,  3.5049e-01,\n",
            "         -1.1249e-01, -2.1471e-01, -3.8439e-01, -1.0760e-01, -8.8821e-02,\n",
            "          2.5263e-01,  2.1448e-01,  5.5799e-02, -6.5411e-02,  9.9837e-02,\n",
            "          3.3435e-01,  2.4018e-01,  2.9875e-02, -1.1191e-01,  5.4330e-01,\n",
            "         -5.5214e-01,  1.1125e+00,  5.4141e-01, -7.4160e-02,  3.5337e-01,\n",
            "          1.2313e-01,  3.4855e-02, -2.8568e-01, -1.2517e-01, -4.4332e-02,\n",
            "          1.3323e-01, -2.4995e-01, -4.9833e-01,  4.1959e-01, -3.1580e-01,\n",
            "          6.1942e-01,  3.1113e-01,  4.8846e-01,  6.1518e-01, -3.6326e-02,\n",
            "          2.1294e-02, -3.5715e-01,  5.9126e-01,  1.5102e-01, -2.9641e-01,\n",
            "          2.9441e-01, -1.4138e-01,  1.1662e-01, -3.6223e-01, -1.4621e-01,\n",
            "          6.5254e-02,  3.9270e-01,  3.8543e-01, -2.3996e-01, -3.1482e-01,\n",
            "         -4.6860e-01, -1.1920e-01,  8.6236e-02, -3.4596e-02, -3.6275e-01,\n",
            "         -3.9838e-01, -3.6006e-01, -1.9672e-01, -2.7738e-01, -4.1097e-01,\n",
            "          3.6456e-01, -2.6012e-01,  1.2587e-01,  1.2752e-01,  5.4261e-01,\n",
            "          1.0569e-01,  3.5704e-01,  1.4766e-01,  4.4929e-01, -8.1255e-01,\n",
            "         -3.0409e-02,  5.8063e-02,  2.0699e-01,  6.6129e-01,  3.9243e-01,\n",
            "         -6.8644e-01, -8.3415e-01, -1.2653e-01,  1.9644e-01, -4.0900e-01,\n",
            "         -6.3777e-02, -1.8780e-01,  7.9473e-02, -1.7443e-01,  3.1936e-01,\n",
            "          3.6761e-01,  4.3044e-01, -1.7471e-01,  1.3718e-01,  1.4272e-01,\n",
            "         -6.0642e-01,  2.3549e-01,  2.7794e-01,  1.0539e-01, -4.5836e-01,\n",
            "         -3.2561e-01,  1.5292e-02, -2.7672e-01, -4.8611e-01,  3.9087e-01,\n",
            "          3.6016e-01,  6.3403e-01, -1.2816e-01, -1.6720e-02, -3.0123e-01,\n",
            "         -1.7321e-01, -6.7296e-01, -2.7015e-01, -1.2534e-01, -8.0565e-01,\n",
            "          3.6115e-01,  1.7370e-01, -3.5578e-01, -2.1725e+00, -2.8102e-02,\n",
            "         -2.6773e-02, -2.2444e-01,  3.1249e-02,  6.4420e-02, -1.5017e-01,\n",
            "         -3.4460e-01, -5.5676e-01,  1.8039e-01, -4.2200e-01, -9.1074e-01,\n",
            "         -3.1339e-03,  7.2439e-01,  3.9006e-01, -4.4129e-02, -4.4785e-02,\n",
            "          2.8707e-02, -1.2432e-01,  6.9166e-01, -1.3227e-02, -2.3540e-02,\n",
            "         -7.0615e-02, -4.5062e-01,  4.5705e-01,  3.3198e-01, -2.2727e-01,\n",
            "          3.2434e-01, -4.5709e-01, -5.1586e-01, -1.5693e-01, -1.0897e-01,\n",
            "          3.9317e-01, -2.5950e-01, -1.5326e-01,  3.3276e-01,  3.2522e-01,\n",
            "         -2.5241e-01,  4.7946e-01, -3.7339e-01, -2.8146e-01,  7.7628e-02,\n",
            "          2.7131e-01, -3.7212e-01,  6.1400e-01, -2.9269e-01, -4.4389e-01,\n",
            "         -3.7750e-01,  2.7135e-01,  3.6869e-01, -1.6904e-01, -1.7583e-01,\n",
            "          2.9626e-01,  2.9393e-01, -8.2036e-03,  3.4545e-02,  4.5846e-01,\n",
            "          3.0137e-01,  1.6171e-01, -2.7772e-01,  5.2397e-01, -6.1950e-01,\n",
            "         -2.4818e-02, -5.1942e-02,  3.6764e-01, -5.8404e-01, -2.6651e-01,\n",
            "         -7.5761e-02, -1.7428e-01,  4.1535e-01, -2.7556e-01, -5.6796e-02,\n",
            "         -4.3509e-01, -9.6659e-01, -1.1800e-01, -3.8004e-01,  2.7555e-01,\n",
            "         -2.9743e-01,  2.4023e-01, -3.8869e-01, -4.0248e-01, -8.3882e-01,\n",
            "         -1.0652e-01, -9.4192e-02,  1.4810e-01,  9.0844e-03,  1.4658e-01,\n",
            "         -1.4813e-01, -1.6078e-01, -4.3130e-01, -8.0683e-02,  4.3722e-01,\n",
            "          4.2623e-01,  3.3201e-01, -2.8283e-01,  2.0751e-01,  5.9093e-01,\n",
            "         -6.3453e-01,  5.7386e-01, -2.9870e-01,  1.0221e-02, -4.7624e-01,\n",
            "          4.9509e-01,  4.7470e-02,  1.3193e-01,  3.6281e-01, -1.1642e+00,\n",
            "          3.8372e-01,  1.7071e-01,  3.8881e-01,  1.7703e-01, -4.7019e-01,\n",
            "          1.2768e-01, -1.3409e-01, -2.8794e-01,  3.2066e-01, -3.7853e-01,\n",
            "          4.6259e-01,  5.2343e-01,  3.0741e-01,  2.7410e-01,  4.9933e-01,\n",
            "         -5.6466e-01, -3.4677e-01, -6.6571e-01, -1.3347e-01, -8.5910e-02,\n",
            "          6.2487e-02, -3.9922e-01, -3.5880e-01, -5.8337e-01, -1.3556e-02,\n",
            "         -1.6812e-01,  1.3949e-01,  2.9142e-01, -4.5623e-01, -1.0705e-01,\n",
            "          6.6569e-01,  7.6614e-01, -1.9306e-01,  4.3854e-01,  2.8110e-01,\n",
            "         -3.6835e-01, -1.6012e-01, -2.5005e-01,  7.6297e-01,  1.9653e-01,\n",
            "         -1.8120e-01,  1.1895e-03,  1.8755e-01, -1.8990e-01, -2.3725e-01,\n",
            "          3.2633e-02, -2.7723e-01, -4.7986e-02, -6.2332e-01,  2.6807e-01,\n",
            "         -1.2293e-01, -2.7098e-01, -6.9677e-01,  1.5738e-01,  5.3557e-01,\n",
            "          1.2760e-01, -1.7979e-02,  1.2769e-01, -5.6453e-02,  6.7965e-02,\n",
            "          1.8555e-01, -3.6374e-01,  2.8518e-01, -4.3920e-01, -2.4276e-01,\n",
            "          5.1755e-01, -2.3519e-01,  6.4010e-02,  3.9268e-01,  5.7986e-01,\n",
            "         -1.7500e-01,  7.1669e-02,  5.7915e-01,  5.1699e-02, -1.1085e-03,\n",
            "         -4.8444e-02,  1.5531e-01,  2.8402e-01,  6.8268e-01,  8.1524e-02,\n",
            "          1.5325e-01,  1.9466e-01,  1.2260e-02, -3.3223e-01,  2.5763e-02,\n",
            "         -1.6071e-01, -3.7663e-01, -7.3670e-01, -5.0067e-01,  1.1540e-01,\n",
            "         -3.3788e-01,  1.2889e-01,  2.1528e-02,  6.1149e-01,  3.3550e-01,\n",
            "         -2.0217e-01, -6.3961e-02,  2.4056e-02, -9.3070e-02, -2.7771e-02,\n",
            "          1.8373e-01, -4.1812e-02, -1.0456e-01, -2.7569e-01, -3.9216e-01,\n",
            "         -3.2092e-01, -1.0158e+00,  1.6407e-01,  4.5044e-02,  2.3079e-01,\n",
            "          2.6936e-02, -2.1047e-01, -3.1392e-01, -4.6154e-01, -4.0347e-01,\n",
            "          7.3271e-02,  1.1470e-01, -2.4129e-01, -3.6199e-01, -5.3254e-01,\n",
            "         -5.2185e-01, -4.0713e-01,  2.1619e-02,  1.4186e-01, -1.2105e-01,\n",
            "         -1.4055e-02, -4.2986e-02, -1.2459e-01, -6.6652e-01, -6.4169e-01,\n",
            "         -2.2399e-01,  6.2557e-02, -3.3323e-01,  1.8865e-02,  1.6465e-01,\n",
            "         -2.8729e-02, -5.9477e-01,  2.0963e-02, -3.3761e-01,  1.8088e-01,\n",
            "          7.4363e-01,  1.5554e-01,  2.7824e-01, -2.1975e-01,  5.1316e-01,\n",
            "         -3.9708e-01, -2.4769e-01,  4.3027e-01, -2.3078e-01, -2.9392e-01,\n",
            "          1.3250e-01, -6.1646e-01,  2.6501e-01,  5.6891e-01, -1.3585e-01,\n",
            "         -1.2774e-01,  8.1189e-01,  3.6497e-01,  5.0178e-01,  2.9736e-01,\n",
            "          8.7772e-01,  7.3390e-02,  2.5788e-01, -3.3609e-01,  8.8207e-02,\n",
            "          2.1282e-02,  1.4487e-01,  7.6676e-03, -3.9123e-01, -6.3919e-02,\n",
            "         -3.7236e-01,  8.2942e-02,  3.0821e-02,  3.1530e-02,  2.0262e-01,\n",
            "         -5.0065e-01, -1.2373e-01,  2.2661e-01,  1.6069e-01, -3.6415e-01,\n",
            "          2.3418e-01, -1.6900e-01, -1.3540e-01, -1.6677e-01,  1.5227e-01,\n",
            "         -2.6064e-01,  4.4845e-02, -3.4592e-02, -1.2043e-01,  6.4724e-01,\n",
            "          4.8944e-01, -3.0347e-01, -2.3118e-01, -8.3765e-02,  2.2163e-01,\n",
            "          1.0404e-01,  1.3495e-01, -5.3097e-01,  1.4525e-01,  4.9890e-01,\n",
            "         -4.9265e-01,  3.7358e-01,  2.2077e-01, -5.4249e-02, -6.7141e-02,\n",
            "          6.2194e-01,  4.6524e-01, -4.2303e-01, -3.2715e-01,  3.8370e-01,\n",
            "         -5.7111e-01, -1.6922e-01,  4.2353e-01, -2.0156e-01, -1.2482e-01,\n",
            "          4.3334e-01, -4.0269e-02, -5.8663e-01,  7.2658e-01, -5.5645e-01,\n",
            "         -5.7467e-02, -2.1052e-01,  1.0038e-01, -2.5418e-03,  7.7563e-01,\n",
            "         -3.9355e-01,  6.4184e-01, -5.9658e-01,  2.1974e-02,  1.8323e-01,\n",
            "          1.7593e-01,  4.8541e-01, -4.6240e-01,  3.5692e-01,  3.2622e-01,\n",
            "         -2.0756e-01,  5.7904e-01, -2.7194e-01, -5.2925e-01,  7.4888e-02,\n",
            "         -2.6069e-02,  3.5997e-01,  5.5750e-01,  3.2160e-01,  4.0078e-01,\n",
            "          5.1017e-01, -4.6595e-02,  2.9056e-01,  2.4928e-01,  2.0993e-01,\n",
            "          4.9611e-01, -4.1696e-02, -1.5711e-01,  1.5638e-01,  8.1300e-02,\n",
            "          3.2564e-01, -2.6684e-01, -2.1355e-01,  1.9676e-01,  4.6960e-01,\n",
            "          1.5972e-01, -2.5918e-01, -1.0547e-01,  1.3562e-01,  3.5989e-01,\n",
            "         -1.0882e-01, -7.1567e-02, -5.3039e-01,  8.8760e-01, -3.4283e-01,\n",
            "         -5.0051e-02, -4.8836e-01,  2.0944e-01,  2.6859e-01,  4.4360e-01,\n",
            "         -4.6622e-01, -1.3640e-01, -1.4363e-01, -3.5663e-01, -1.1210e-01,\n",
            "         -1.9890e-01, -1.2909e-01, -3.0789e-03, -6.2015e-02, -4.2345e-01,\n",
            "          2.7059e-01, -3.1317e-01,  5.7516e-01, -2.2513e-03,  1.7034e-01,\n",
            "          3.9410e-01,  8.1126e-01, -3.6260e-01,  5.2088e-01, -5.4591e-01,\n",
            "         -5.8637e-02,  1.5576e-01,  1.7441e-01,  1.3422e-01, -4.4368e-01,\n",
            "          2.6824e-01, -2.6424e-01, -5.6734e-01,  2.7222e-01,  5.5829e-01,\n",
            "         -9.1910e-01,  2.2039e-01, -3.5612e-01,  1.3164e-01, -1.1517e-01,\n",
            "         -2.0684e-01, -2.7871e-02,  3.9112e-01, -6.6897e-01, -3.8353e-01,\n",
            "         -5.6089e-02,  8.0477e-01, -2.5700e-01, -1.0725e-01,  7.5041e-02,\n",
            "          2.4736e-01, -6.1457e-01, -1.9508e-01,  5.4606e-01,  3.3887e-01,\n",
            "          2.7338e-01,  4.4597e-01,  4.4805e-01, -7.3450e-01,  2.2959e-01,\n",
            "         -3.8097e-02, -1.4963e-01, -2.4957e-01, -2.8457e-01,  5.6483e-01,\n",
            "          5.4733e-02,  8.0649e-02, -1.2184e+00,  5.7510e-01,  1.3625e-01,\n",
            "         -4.4055e-01,  6.9751e-02, -4.0260e-01,  1.0932e-01, -6.6830e-02,\n",
            "         -3.9555e-02, -5.4193e-01, -4.4191e-01,  2.4927e-01,  6.6517e-01,\n",
            "         -1.7534e-01, -1.2388e-01,  3.1970e-01]])\n",
            "\n",
            "Kích thước của vector: torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gdpP4A8u27Hg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}