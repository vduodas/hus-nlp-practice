{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8428973",
   "metadata": {},
   "source": [
    "BƯỚC 0: THIẾT LẬP MÔI TRƯỜNG VÀ TẢI DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6833a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8954, 2)\n",
      "Validation shape: (1076, 2)\n",
      "Test shape: (1076, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what alarms do i have set right now</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>checkout today alarm of meeting</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report alarm settings</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see see for me the alarms that you have set to...</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there an alarm for ten am</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     category\n",
       "0                what alarms do i have set right now  alarm_query\n",
       "1                    checkout today alarm of meeting  alarm_query\n",
       "2                              report alarm settings  alarm_query\n",
       "3  see see for me the alarms that you have set to...  alarm_query\n",
       "4                       is there an alarm for ten am  alarm_query"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data paths\n",
    "train_path = \"C:\\\\Users\\\\DoubleDD\\\\HUS\\\\NLP&DL\\\\datasets\\\\hwu\\\\train.csv\"\n",
    "val_path = \"C:\\\\Users\\\\DoubleDD\\\\HUS\\\\NLP&DL\\\\datasets\\\\hwu\\\\val.csv\"\n",
    "test_path = \"C:\\\\Users\\\\DoubleDD\\\\HUS\\\\NLP&DL\\\\datasets\\\\hwu\\\\test.csv\"\n",
    "\n",
    "# Đọc các file dữ liệu\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", val_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab30176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alarm_query': 0, 'alarm_remove': 1, 'alarm_set': 2, 'audio_volume_down': 3, 'audio_volume_mute': 4, 'audio_volume_up': 5, 'calendar_query': 6, 'calendar_remove': 7, 'calendar_set': 8, 'cooking_recipe': 9, 'datetime_convert': 10, 'datetime_query': 11, 'email_addcontact': 12, 'email_query': 13, 'email_querycontact': 14, 'email_sendemail': 15, 'general_affirm': 16, 'general_commandstop': 17, 'general_confirm': 18, 'general_dontcare': 19, 'general_explain': 20, 'general_joke': 21, 'general_negate': 22, 'general_praise': 23, 'general_quirky': 24, 'general_repeat': 25, 'iot_cleaning': 26, 'iot_coffee': 27, 'iot_hue_lightchange': 28, 'iot_hue_lightdim': 29, 'iot_hue_lightoff': 30, 'iot_hue_lighton': 31, 'iot_hue_lightup': 32, 'iot_wemo_off': 33, 'iot_wemo_on': 34, 'lists_createoradd': 35, 'lists_query': 36, 'lists_remove': 37, 'music_likeness': 38, 'music_query': 39, 'music_settings': 40, 'news_query': 41, 'play_audiobook': 42, 'play_game': 43, 'play_music': 44, 'play_podcasts': 45, 'play_radio': 46, 'qa_currency': 47, 'qa_definition': 48, 'qa_factoid': 49, 'qa_maths': 50, 'qa_stock': 51, 'recommendation_events': 52, 'recommendation_locations': 53, 'recommendation_movies': 54, 'social_post': 55, 'social_query': 56, 'takeaway_order': 57, 'takeaway_query': 58, 'transport_query': 59, 'transport_taxi': 60, 'transport_ticket': 61, 'transport_traffic': 62, 'weather_query': 63}\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder theo đúng nguyên tắc ML:\n",
    "    # fit trên toàn bộ tập dữ liệu “category” (gồm train + val + test)\n",
    "    # sau đó transform riêng cho train/val/test\n",
    "    # tránh lỗi “unseen labels” và đảm bảo mapping nhất quán.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 3 dataframe:\n",
    "# train_df, val_df, test_df\n",
    "# và mỗi dataframe có cột: \"category\"\n",
    "\n",
    "# 1. Gộp toàn bộ giá trị category để fit encoder (không ghép dataframe)\n",
    "all_categories = pd.concat([\n",
    "    train_df[\"category\"],\n",
    "    val_df[\"category\"],\n",
    "    test_df[\"category\"]\n",
    "]).astype(str)\n",
    "\n",
    "# 2. Fit LabelEncoder trên toàn bộ unique categories\n",
    "le = LabelEncoder()\n",
    "le.fit(all_categories)\n",
    "\n",
    "# 3. Transform từng tập riêng biệt\n",
    "train_df[\"category_encoded\"] = le.transform(train_df[\"category\"].astype(str))\n",
    "val_df[\"category_encoded\"] = le.transform(val_df[\"category\"].astype(str))\n",
    "test_df[\"category_encoded\"] = le.transform(test_df[\"category\"].astype(str))\n",
    "\n",
    "# Kiểm tra mapping\n",
    "mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(mapping)\n",
    "\n",
    "# Số lượng categories\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "num_classes = len(train_df[\"category_encoded\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7da66",
   "metadata": {},
   "source": [
    "Nhiệm vụ 1: (Warm-up Ôn bài cũ) Pipeline TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6da7721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        19\n",
      "           1       1.00      0.73      0.84        11\n",
      "           2       0.77      0.89      0.83        19\n",
      "           3       1.00      0.75      0.86         8\n",
      "           4       0.92      0.80      0.86        15\n",
      "           5       0.93      1.00      0.96        13\n",
      "           6       0.45      0.53      0.49        19\n",
      "           7       0.89      0.89      0.89        19\n",
      "           8       0.87      0.68      0.76        19\n",
      "           9       0.59      0.68      0.63        19\n",
      "          10       0.67      0.75      0.71         8\n",
      "          11       0.74      0.89      0.81        19\n",
      "          12       0.78      0.88      0.82         8\n",
      "          13       0.83      0.79      0.81        19\n",
      "          14       0.92      0.63      0.75        19\n",
      "          15       0.81      0.89      0.85        19\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       0.90      1.00      0.95        19\n",
      "          20       1.00      0.95      0.97        19\n",
      "          21       1.00      1.00      1.00        12\n",
      "          22       0.95      1.00      0.97        19\n",
      "          23       0.95      1.00      0.97        19\n",
      "          24       0.36      0.26      0.30        19\n",
      "          25       0.90      1.00      0.95        19\n",
      "          26       1.00      1.00      1.00        16\n",
      "          27       1.00      0.95      0.97        19\n",
      "          28       0.75      0.79      0.77        19\n",
      "          29       0.91      0.83      0.87        12\n",
      "          30       0.89      0.89      0.89        19\n",
      "          31       0.67      0.67      0.67         3\n",
      "          32       1.00      0.86      0.92        14\n",
      "          33       0.80      0.89      0.84         9\n",
      "          34       0.78      1.00      0.88         7\n",
      "          35       0.68      0.79      0.73        19\n",
      "          36       0.75      0.79      0.77        19\n",
      "          37       0.85      0.89      0.87        19\n",
      "          38       0.65      0.61      0.63        18\n",
      "          39       0.71      0.53      0.61        19\n",
      "          40       1.00      0.57      0.73         7\n",
      "          41       0.75      0.63      0.69        19\n",
      "          42       0.95      0.95      0.95        19\n",
      "          43       0.81      0.68      0.74        19\n",
      "          44       0.58      0.74      0.65        19\n",
      "          45       1.00      0.84      0.91        19\n",
      "          46       0.89      0.84      0.86        19\n",
      "          47       0.94      0.89      0.92        19\n",
      "          48       0.82      0.95      0.88        19\n",
      "          49       0.48      0.58      0.52        19\n",
      "          50       0.92      0.86      0.89        14\n",
      "          51       1.00      0.95      0.97        19\n",
      "          52       0.83      0.79      0.81        19\n",
      "          53       0.81      0.89      0.85        19\n",
      "          54       1.00      1.00      1.00        10\n",
      "          55       0.95      1.00      0.97        19\n",
      "          56       0.80      0.89      0.84        18\n",
      "          57       0.83      0.79      0.81        19\n",
      "          58       0.89      0.89      0.89        19\n",
      "          59       0.68      0.79      0.73        19\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.94      0.79      0.86        19\n",
      "          62       1.00      0.95      0.97        19\n",
      "          63       0.62      0.68      0.65        19\n",
      "\n",
      "    accuracy                           0.84      1076\n",
      "   macro avg       0.85      0.83      0.84      1076\n",
      "weighted avg       0.84      0.84      0.84      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df[\"category_encoded\"]\n",
    "\n",
    "X_test = test_df[\"text\"]\n",
    "y_test = test_df[\"category_encoded\"]\n",
    "# 1. Tạo pipeline TF-IDF + Logistic Regression\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# 2. Huấn luyện pipeline trên tập train\n",
    "tfidf_lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 3. Dự đoán trên tập test\n",
    "y_pred = tfidf_lr_pipeline.predict(X_test)\n",
    "\n",
    "# 4. Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c5f58",
   "metadata": {},
   "source": [
    "Nhiệm vụ 2: (Warm-up Ôn bài cũ) Pipeline Word2Vec (Trung bình) + Dense\n",
    "Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a0b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Huấn luyện word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [text.split() for text in train_df[\"text\"]]\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb73ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Hàm chuyển câu → vector trung bình\n",
    "def sentence_to_avg_vector(text, model):\n",
    "    words = text.split()\n",
    "    vectors = [model.wv[w] for w in words if w in model.wv]\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f4b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Tạo dữ liệu vector cho train / val / test\n",
    "X_train_avg = np.vstack([\n",
    "    sentence_to_avg_vector(text, w2v_model)\n",
    "    for text in train_df[\"text\"]\n",
    "])\n",
    "\n",
    "X_val_avg = np.vstack([\n",
    "    sentence_to_avg_vector(text, w2v_model)\n",
    "    for text in val_df[\"text\"]\n",
    "])\n",
    "\n",
    "X_test_avg = np.vstack([\n",
    "    sentence_to_avg_vector(text, w2v_model)\n",
    "    for text in test_df[\"text\"]\n",
    "])\n",
    "\n",
    "y_train = train_df[\"category_encoded\"]\n",
    "y_val = val_df[\"category_encoded\"]\n",
    "y_test = test_df[\"category_encoded\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2383617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DoubleDD\\VSC_Workspace\\VSCode_Python\\common-venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Mô hình Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "dense_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "# dense_model = Sequential([\n",
    "#     Input(shape=(w2v_model.vector_size,)),   # Khai báo input rõ ràng\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# dense_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c74da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0219 - loss: 4.1472 - val_accuracy: 0.0344 - val_loss: 4.1140\n",
      "Epoch 2/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0362 - loss: 4.1086 - val_accuracy: 0.0716 - val_loss: 4.0670\n",
      "Epoch 3/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0506 - loss: 4.0408 - val_accuracy: 0.0669 - val_loss: 3.9751\n",
      "Epoch 4/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0561 - loss: 3.9497 - val_accuracy: 0.0641 - val_loss: 3.8679\n",
      "Epoch 5/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0640 - loss: 3.8551 - val_accuracy: 0.0892 - val_loss: 3.7616\n",
      "Epoch 6/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0726 - loss: 3.7680 - val_accuracy: 0.0985 - val_loss: 3.6706\n",
      "Epoch 7/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0803 - loss: 3.6926 - val_accuracy: 0.1106 - val_loss: 3.6052\n",
      "Epoch 8/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0915 - loss: 3.6359 - val_accuracy: 0.1283 - val_loss: 3.5400\n",
      "Epoch 9/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1012 - loss: 3.5865 - val_accuracy: 0.1329 - val_loss: 3.4872\n",
      "Epoch 10/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1079 - loss: 3.5339 - val_accuracy: 0.1487 - val_loss: 3.4409\n",
      "Epoch 11/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1125 - loss: 3.5059 - val_accuracy: 0.1487 - val_loss: 3.4076\n",
      "Epoch 12/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1163 - loss: 3.4740 - val_accuracy: 0.1599 - val_loss: 3.3700\n",
      "Epoch 13/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1203 - loss: 3.4391 - val_accuracy: 0.1533 - val_loss: 3.3406\n",
      "Epoch 14/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1303 - loss: 3.4035 - val_accuracy: 0.1524 - val_loss: 3.3322\n",
      "Epoch 15/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1294 - loss: 3.3893 - val_accuracy: 0.1682 - val_loss: 3.2697\n",
      "Epoch 16/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1383 - loss: 3.3626 - val_accuracy: 0.1757 - val_loss: 3.2589\n",
      "Epoch 17/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1386 - loss: 3.3399 - val_accuracy: 0.1747 - val_loss: 3.2316\n",
      "Epoch 18/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1445 - loss: 3.3200 - val_accuracy: 0.1784 - val_loss: 3.2073\n",
      "Epoch 19/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1469 - loss: 3.2969 - val_accuracy: 0.1803 - val_loss: 3.1916\n",
      "Epoch 20/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1459 - loss: 3.2836 - val_accuracy: 0.1840 - val_loss: 3.1806\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1775 - loss: 3.2033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.203279733657837, 0.17750929296016693]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.5 Huấn luyện và đánh giá\n",
    "dense_model.fit(\n",
    "    X_train_avg, y_train,\n",
    "    validation_data=(X_val_avg, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "dense_model.evaluate(X_test_avg, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04346523",
   "metadata": {},
   "source": [
    "Nhiệm vụ 3: Mô hình Nâng cao (Embedding Pre-trained + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5ccec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Tokenizer và padding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "max_len = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(train_df[\"text\"])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_df[\"text\"])\n",
    "X_val_seq = tokenizer.texts_to_sequences(val_df[\"text\"])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_df[\"text\"])\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3100f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Tạo embedding matrix từ Word2vec\n",
    "embedding_dim = w2v_model.vector_size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69801925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DoubleDD\\VSC_Workspace\\VSCode_Python\\common-venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Mô hình LSTM (Embedding pre-trained)\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "lstm_model_pretrained = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_len,\n",
    "        trainable=False\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model_pretrained.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d04302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.0198 - loss: 4.1334 - val_accuracy: 0.0400 - val_loss: 4.0386\n",
      "Epoch 2/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.0356 - loss: 4.0026 - val_accuracy: 0.0502 - val_loss: 3.8625\n",
      "Epoch 3/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.0380 - loss: 3.9966 - val_accuracy: 0.0483 - val_loss: 3.8370\n",
      "Epoch 4/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.0482 - loss: 3.8708 - val_accuracy: 0.0539 - val_loss: 3.7793\n",
      "Epoch 5/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.0533 - loss: 3.8285 - val_accuracy: 0.0743 - val_loss: 3.7240\n",
      "Epoch 6/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.0586 - loss: 3.7932 - val_accuracy: 0.0716 - val_loss: 3.6785\n",
      "Epoch 7/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.0599 - loss: 3.7390 - val_accuracy: 0.0855 - val_loss: 3.6303\n",
      "Epoch 8/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.0665 - loss: 3.6843 - val_accuracy: 0.0734 - val_loss: 3.6094\n",
      "Epoch 9/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.0714 - loss: 3.6460 - val_accuracy: 0.0911 - val_loss: 3.5236\n",
      "Epoch 10/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.0730 - loss: 3.5972 - val_accuracy: 0.0864 - val_loss: 3.4830\n",
      "Epoch 11/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.0830 - loss: 3.5719 - val_accuracy: 0.0836 - val_loss: 3.5528\n",
      "Epoch 12/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.0818 - loss: 3.5294 - val_accuracy: 0.1050 - val_loss: 3.4551\n",
      "Epoch 13/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 65ms/step - accuracy: 0.0821 - loss: 3.5229 - val_accuracy: 0.1022 - val_loss: 3.4221\n",
      "Epoch 14/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 84ms/step - accuracy: 0.0848 - loss: 3.4991 - val_accuracy: 0.1097 - val_loss: 3.4011\n",
      "Epoch 15/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.0933 - loss: 3.4923 - val_accuracy: 0.0976 - val_loss: 3.4436\n",
      "Epoch 16/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.0868 - loss: 3.5067 - val_accuracy: 0.1097 - val_loss: 3.3910\n",
      "Epoch 17/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.0900 - loss: 3.4927 - val_accuracy: 0.1059 - val_loss: 3.3653\n",
      "Epoch 18/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.0986 - loss: 3.4793 - val_accuracy: 0.1078 - val_loss: 3.4016\n",
      "Epoch 19/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.0916 - loss: 3.5014 - val_accuracy: 0.1097 - val_loss: 3.4000\n",
      "Epoch 20/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.0946 - loss: 3.4808 - val_accuracy: 0.1069 - val_loss: 3.3964\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1041 - loss: 3.3833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3832900524139404, 0.10408922284841537]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4 Huấn luyện và đánh giá\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lstm_model_pretrained.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "lstm_model_pretrained.evaluate(X_test_pad, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9a1f7",
   "metadata": {},
   "source": [
    "Nhiệm vụ 4: Mô hình Nâng cao (Embedding học từ đầu + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5341863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DoubleDD\\VSC_Workspace\\VSCode_Python\\common-venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.0153 - loss: 4.1441 - val_accuracy: 0.0177 - val_loss: 4.1289\n",
      "Epoch 2/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.0152 - loss: 4.1367 - val_accuracy: 0.0177 - val_loss: 4.1299\n",
      "Epoch 3/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.0168 - loss: 4.1349 - val_accuracy: 0.0177 - val_loss: 4.1271\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0177 - loss: 4.1289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.128947734832764, 0.017657993361353874]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model_scratch = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=100,\n",
    "        input_length=max_len\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model_scratch.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lstm_model_scratch.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "lstm_model_scratch.evaluate(X_test_pad, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fc17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
