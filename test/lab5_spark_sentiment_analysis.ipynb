{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d86b6dc",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Spark ML Pipeline\n",
    "\n",
    "#### Objective\n",
    "- Build a scalable text classification pipeline using PySpark, including:\n",
    "- Text preprocessing\n",
    "- Feature extraction (TF-IDF)\n",
    "- Logistic Regression classification\n",
    "- Model evaluation\n",
    "\n",
    "#### Dataset Description\n",
    "\n",
    "The dataset (sentiments.csv) contains two columns:\n",
    "- `text`: textual content\n",
    "- `sentiment`: sentiment label (-1 = negative, 1 = positive)\n",
    "\n",
    "The labels are normalized to:\n",
    "- 0 → negative\n",
    "- 1 → positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507187a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thư viện\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    Tokenizer,\n",
    "    StopWordsRemover,\n",
    "    HashingTF,\n",
    "    IDF\n",
    ")\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06d15448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# khởi tạo spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"SentimentAnalysis\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1874d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|Kickers on my wat...|        1|\n",
      "|user: AAP MOVIE. ...|        1|\n",
      "|user I'd be afrai...|        1|\n",
      "|   MNTA Over 12.00  |        1|\n",
      "|    OI  Over 21.37  |        1|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data_path = r\"C:\\Users\\DoubleDD\\HUS\\NLP&DL\\datasets\\sentiments.csv\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    data_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a663d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+\n",
      "|                text|sentiment|label|\n",
      "+--------------------+---------+-----+\n",
      "|Kickers on my wat...|        1|  1.0|\n",
      "|user: AAP MOVIE. ...|        1|  1.0|\n",
      "|user I'd be afrai...|        1|  1.0|\n",
      "|   MNTA Over 12.00  |        1|  1.0|\n",
      "|    OI  Over 21.37  |        1|  1.0|\n",
      "+--------------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert sentiment labels from {-1, 1} to {0, 1}\n",
    "df = df.withColumn(\n",
    "    \"label\",\n",
    "    (col(\"sentiment\").cast(\"integer\") + 1) / 2\n",
    ")\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "\n",
    "df.select(\"text\", \"sentiment\", \"label\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b6ad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4682\n",
      "Testing samples: 1109\n"
     ]
    }
   ],
   "source": [
    "# chia train/test theo tỉ lệ  8:2\n",
    "trainingData, testData = df.randomSplit(\n",
    "    [0.8, 0.2],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {trainingData.count()}\")\n",
    "print(f\"Testing samples: {testData.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a71095f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline tiền xử lý\n",
    "tokenizer = Tokenizer(\n",
    "    inputCol=\"text\",\n",
    "    outputCol=\"words\"\n",
    ")\n",
    "\n",
    "stopwordsRemover = StopWordsRemover(\n",
    "    inputCol=\"words\",\n",
    "    outputCol=\"filtered_words\"\n",
    ")\n",
    "\n",
    "hashingTF = HashingTF(\n",
    "    inputCol=\"filtered_words\",\n",
    "    outputCol=\"raw_features\",\n",
    "    numFeatures=10000\n",
    ")\n",
    "\n",
    "idf = IDF(\n",
    "    inputCol=\"raw_features\",\n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e581613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mô hình Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    maxIter=10,\n",
    "    regParam=0.001,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7117f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ghép các module trên thành 1 Spark ML Pipeline\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        tokenizer,\n",
    "        stopwordsRemover,\n",
    "        hashingTF,\n",
    "        idf,\n",
    "        lr\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "858c3728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+-----+----------+------------------------------------------+\n",
      "|                                                                            text|label|prediction|                               probability|\n",
      "+--------------------------------------------------------------------------------+-----+----------+------------------------------------------+\n",
      "|  ISG An update to our Feb 20th video review..if it closes below 495 much low...|  0.0|       1.0|   [0.2614599786780246,0.7385400213219754]|\n",
      "|  The rodeo clown sent BK screaming into the SI weekly red zone...time to pee...|  0.0|       0.0| [0.9999997991875168,2.008124831975877E-7]|\n",
      "|                            , ES,SPY, Ground Hog Week, distribution at highs..  |  0.0|       1.0|   [0.0541093238048886,0.9458906761951114]|\n",
      "|                                                        ES, S  PAT TWO, update  |  0.0|       0.0|[0.9986626113379365,0.0013373886620634545]|\n",
      "|               PCN doulble top at key fib retracement weekly....time to exit ...|  0.0|       1.0|   [0.4465277905840951,0.5534722094159049]|\n",
      "| also not very healthy, fell back below DT line after breaking it, SI weak, M...|  0.0|       1.0|     [0.411208715444323,0.588791284555677]|\n",
      "| thinking out loud. 50 mva sub 200 mva- done. Bottoming tails at 61.60 provid...|  1.0|       0.0| [0.9999330359141018,6.696408589823566E-5]|\n",
      "|\"RT @WSJheard: Canâ€™t get your hands on a Nintendo console to play the new v...|  1.0|       1.0|  [0.02223734716793978,0.9777626528320602]|\n",
      "|#ContrAlert Don't Panic: Wall Street Is Going Crazy For Student oans -- But I...|  0.0|       1.0|[0.0011823087987717232,0.9988176912012283]|\n",
      "|#CoronavirusPandemic As bad as #China's economic dive is, the slump is even m...|  0.0|       0.0|[0.9951744604080517,0.0048255395919483135]|\n",
      "+--------------------------------------------------------------------------------+-----+----------+------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train mô hình\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "\n",
    "# dự đoán\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\n",
    "    \"text\",\n",
    "    \"label\",\n",
    "    \"prediction\",\n",
    "    \"probability\"\n",
    ").show(10, truncate=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b80346e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Results ===\n",
      "Accuracy : 0.7295\n",
      "F1-score : 0.7266\n"
     ]
    }
   ],
   "source": [
    "# đánh giá mô hình\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"=== Evaluation Results ===\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba4e4",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "**Accuracy/F1 ~ 0.73** là hợp lý đối với mô hình baseline sử dụng\n",
    "**TF-IDF kết hợp với Logistic Regression**.\n",
    "\n",
    "Ở phần cải tiến (kỳ vọng cho ra kết quả tốt hơn), em thay thế Logistic Regression bằng **Naive Bayes** trong khi\n",
    "giữ nguyên đặc trưng TF-IDF. Naive Bayes là mô hình xác suất đơn giản nhưng\n",
    "thường cho hiệu quả tốt trong các bài toán phân loại văn bản, đặc biệt khi\n",
    "đặc trưng đầu vào là các vector TF-IDF không âm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e0d429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import và khai báo mô hình\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "\n",
    "nb = NaiveBayes(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    smoothing=1.0,\n",
    "    modelType=\"multinomial\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "292bbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline Naive Bayes thay vì LR\n",
    "pipeline_nb = Pipeline(\n",
    "    stages=[\n",
    "        tokenizer,\n",
    "        stopwordsRemover,\n",
    "        hashingTF,\n",
    "        idf,\n",
    "        nb\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Improved Model (Naive Bayes) ===\n",
      "Accuracy : 0.6844\n",
      "F1-score : 0.6842\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model_nb = pipeline_nb.fit(trainingData)\n",
    "\n",
    "# dự đoán\n",
    "predictions_nb = model_nb.transform(testData)\n",
    "\n",
    "accuracy_nb = accuracy_evaluator.evaluate(predictions_nb)\n",
    "f1_nb = f1_evaluator.evaluate(predictions_nb)\n",
    "\n",
    "print(\"=== Improved Model (Naive Bayes) ===\")\n",
    "print(f\"Accuracy : {accuracy_nb:.4f}\")\n",
    "print(f\"F1-score : {f1_nb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7838a5",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "- Mô hình baseline sử dụng **TF-IDF kết hợp với Logistic Regression** đạt\n",
    "Accuracy/F1 khoảng **0.73**, cho thấy đây là một cấu hình ổn định đối với\n",
    "bài toán phân loại cảm xúc.\n",
    "\n",
    "- Trong phần cải tiến, em thay thế Logistic Regression bằng **Naive Bayes**\n",
    "trong khi giữ nguyên đặc trưng TF-IDF. Tuy nhiên, kết quả thực nghiệm cho thấy\n",
    "mô hình Naive Bayes không cải thiện hiệu năng so với baseline, thậm chí có\n",
    "xu hướng giảm nhẹ.\n",
    "\n",
    "- Nguyên nhân có thể do giả định độc lập có điều kiện của Naive Bayes chưa phù\n",
    "hợp với dữ liệu thực tế, trong khi Logistic Regression có khả năng học các\n",
    "trọng số đặc trưng linh hoạt hơn. Ngoài ra, kích thước tập dữ liệu tương đối\n",
    "nhỏ cũng khiến Naive Bayes khó phát huy ưu thế của mình.\n",
    "\n",
    "- Kết quả này cho thấy Logistic Regression vẫn là lựa chọn phù hợp hơn cho tập\n",
    "dữ liệu hiện tại, đồng thời nhấn mạnh tầm quan trọng của việc lựa chọn mô hình\n",
    "phù hợp với đặc điểm dữ liệu thay vì chỉ sử dụng các mô hình phức tạp hơn.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
