{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8428973",
   "metadata": {},
   "source": [
    "BƯỚC 0: THIẾT LẬP MÔI TRƯỜNG VÀ TẢI DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6833a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8954, 2)\n",
      "Validation shape: (1076, 2)\n",
      "Test shape: (1076, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what alarms do i have set right now</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>checkout today alarm of meeting</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report alarm settings</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see see for me the alarms that you have set to...</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there an alarm for ten am</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     category\n",
       "0                what alarms do i have set right now  alarm_query\n",
       "1                    checkout today alarm of meeting  alarm_query\n",
       "2                              report alarm settings  alarm_query\n",
       "3  see see for me the alarms that you have set to...  alarm_query\n",
       "4                       is there an alarm for ten am  alarm_query"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data paths\n",
    "train_path = \"C:\\\\Users\\\\DoubleDD\\\\HUS\\\\NLP&DL\\\\datasets\\\\hwu\\\\train.csv\"\n",
    "val_path = \"C:\\\\Users\\\\DoubleDD\\\\HUS\\\\NLP&DL\\\\datasets\\\\hwu\\\\val.csv\"\n",
    "test_path = \"C:\\\\Users\\\\DoubleDD\\\\HUS\\\\NLP&DL\\\\datasets\\\\hwu\\\\test.csv\"\n",
    "\n",
    "# Đọc các file dữ liệu\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", val_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab30176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alarm_query': 0, 'alarm_remove': 1, 'alarm_set': 2, 'audio_volume_down': 3, 'audio_volume_mute': 4, 'audio_volume_up': 5, 'calendar_query': 6, 'calendar_remove': 7, 'calendar_set': 8, 'cooking_recipe': 9, 'datetime_convert': 10, 'datetime_query': 11, 'email_addcontact': 12, 'email_query': 13, 'email_querycontact': 14, 'email_sendemail': 15, 'general_affirm': 16, 'general_commandstop': 17, 'general_confirm': 18, 'general_dontcare': 19, 'general_explain': 20, 'general_joke': 21, 'general_negate': 22, 'general_praise': 23, 'general_quirky': 24, 'general_repeat': 25, 'iot_cleaning': 26, 'iot_coffee': 27, 'iot_hue_lightchange': 28, 'iot_hue_lightdim': 29, 'iot_hue_lightoff': 30, 'iot_hue_lighton': 31, 'iot_hue_lightup': 32, 'iot_wemo_off': 33, 'iot_wemo_on': 34, 'lists_createoradd': 35, 'lists_query': 36, 'lists_remove': 37, 'music_likeness': 38, 'music_query': 39, 'music_settings': 40, 'news_query': 41, 'play_audiobook': 42, 'play_game': 43, 'play_music': 44, 'play_podcasts': 45, 'play_radio': 46, 'qa_currency': 47, 'qa_definition': 48, 'qa_factoid': 49, 'qa_maths': 50, 'qa_stock': 51, 'recommendation_events': 52, 'recommendation_locations': 53, 'recommendation_movies': 54, 'social_post': 55, 'social_query': 56, 'takeaway_order': 57, 'takeaway_query': 58, 'transport_query': 59, 'transport_taxi': 60, 'transport_ticket': 61, 'transport_traffic': 62, 'weather_query': 63}\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder theo đúng nguyên tắc ML:\n",
    "    # fit trên toàn bộ tập dữ liệu “category” (gồm train + val + test)\n",
    "    # sau đó transform riêng cho train/val/test\n",
    "    # tránh lỗi “unseen labels” và đảm bảo mapping nhất quán.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 3 dataframe:\n",
    "# train_df, val_df, test_df\n",
    "# và mỗi dataframe có cột: \"category\"\n",
    "\n",
    "# 1. Gộp toàn bộ giá trị category để fit encoder (không ghép dataframe)\n",
    "all_categories = pd.concat([\n",
    "    train_df[\"category\"],\n",
    "    val_df[\"category\"],\n",
    "    test_df[\"category\"]\n",
    "]).astype(str)\n",
    "\n",
    "# 2. Fit LabelEncoder trên toàn bộ unique categories\n",
    "le = LabelEncoder()\n",
    "le.fit(all_categories)\n",
    "\n",
    "# 3. Transform từng tập riêng biệt\n",
    "train_df[\"category_encoded\"] = le.transform(train_df[\"category\"].astype(str))\n",
    "val_df[\"category_encoded\"] = le.transform(val_df[\"category\"].astype(str))\n",
    "test_df[\"category_encoded\"] = le.transform(test_df[\"category\"].astype(str))\n",
    "\n",
    "# Kiểm tra mapping\n",
    "mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7da66",
   "metadata": {},
   "source": [
    "Nhiệm vụ 1: (Warm-up Ôn bài cũ) Pipeline TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6da7721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        19\n",
      "           1       1.00      0.73      0.84        11\n",
      "           2       0.77      0.89      0.83        19\n",
      "           3       1.00      0.75      0.86         8\n",
      "           4       0.92      0.80      0.86        15\n",
      "           5       0.93      1.00      0.96        13\n",
      "           6       0.45      0.53      0.49        19\n",
      "           7       0.89      0.89      0.89        19\n",
      "           8       0.87      0.68      0.76        19\n",
      "           9       0.59      0.68      0.63        19\n",
      "          10       0.67      0.75      0.71         8\n",
      "          11       0.74      0.89      0.81        19\n",
      "          12       0.78      0.88      0.82         8\n",
      "          13       0.83      0.79      0.81        19\n",
      "          14       0.92      0.63      0.75        19\n",
      "          15       0.81      0.89      0.85        19\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       0.90      1.00      0.95        19\n",
      "          20       1.00      0.95      0.97        19\n",
      "          21       1.00      1.00      1.00        12\n",
      "          22       0.95      1.00      0.97        19\n",
      "          23       0.95      1.00      0.97        19\n",
      "          24       0.36      0.26      0.30        19\n",
      "          25       0.90      1.00      0.95        19\n",
      "          26       1.00      1.00      1.00        16\n",
      "          27       1.00      0.95      0.97        19\n",
      "          28       0.75      0.79      0.77        19\n",
      "          29       0.91      0.83      0.87        12\n",
      "          30       0.89      0.89      0.89        19\n",
      "          31       0.67      0.67      0.67         3\n",
      "          32       1.00      0.86      0.92        14\n",
      "          33       0.80      0.89      0.84         9\n",
      "          34       0.78      1.00      0.88         7\n",
      "          35       0.68      0.79      0.73        19\n",
      "          36       0.75      0.79      0.77        19\n",
      "          37       0.85      0.89      0.87        19\n",
      "          38       0.65      0.61      0.63        18\n",
      "          39       0.71      0.53      0.61        19\n",
      "          40       1.00      0.57      0.73         7\n",
      "          41       0.75      0.63      0.69        19\n",
      "          42       0.95      0.95      0.95        19\n",
      "          43       0.81      0.68      0.74        19\n",
      "          44       0.58      0.74      0.65        19\n",
      "          45       1.00      0.84      0.91        19\n",
      "          46       0.89      0.84      0.86        19\n",
      "          47       0.94      0.89      0.92        19\n",
      "          48       0.82      0.95      0.88        19\n",
      "          49       0.48      0.58      0.52        19\n",
      "          50       0.92      0.86      0.89        14\n",
      "          51       1.00      0.95      0.97        19\n",
      "          52       0.83      0.79      0.81        19\n",
      "          53       0.81      0.89      0.85        19\n",
      "          54       1.00      1.00      1.00        10\n",
      "          55       0.95      1.00      0.97        19\n",
      "          56       0.80      0.89      0.84        18\n",
      "          57       0.83      0.79      0.81        19\n",
      "          58       0.89      0.89      0.89        19\n",
      "          59       0.68      0.79      0.73        19\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.94      0.79      0.86        19\n",
      "          62       1.00      0.95      0.97        19\n",
      "          63       0.62      0.68      0.65        19\n",
      "\n",
      "    accuracy                           0.84      1076\n",
      "   macro avg       0.85      0.83      0.84      1076\n",
      "weighted avg       0.84      0.84      0.84      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df[\"category_encoded\"]\n",
    "\n",
    "X_test = test_df[\"text\"]\n",
    "y_test = test_df[\"category_encoded\"]\n",
    "# 1. Tạo pipeline TF-IDF + Logistic Regression\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# 2. Huấn luyện pipeline trên tập train\n",
    "tfidf_lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 3. Dự đoán trên tập test\n",
    "y_pred = tfidf_lr_pipeline.predict(X_test)\n",
    "\n",
    "# 4. Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c5f58",
   "metadata": {},
   "source": [
    "Nhiệm vụ 2: (Warm-up Ôn bài cũ) Pipeline Word2Vec (Trung bình) + Dense\n",
    "Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0b07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
